# Проект: Рекомендация товаров в электронной коммерции (добавление в корзину)

## Приветсвтие
Привет!
Надеюсь, что все не так плохо, как мне кажется, так как с ограничением времени я смог соорудить только это. Не суди строго.

## Описание

**Цель:** Предсказать, какие товары будут интересны пользователю интернет-магазина для добавлению в корзину.

**Задачи:** 
1. Исследование данных. Проведите первичный анализ данных в Jupyter Notebook и опишите увиденные в них закономерности.	Jupyter Notebook с EDA.
2. Подготовка инфраструктуры. Разверните MLflow с хранилищем артефактов. ..sh-скрипт с запуском и настройкой MLflow.
3. Трансляция. Выберите метрики, которые вы хотите оптимизировать, и решите, как будете решать задачу. Описано в ReadMe.md
4. Моделирование. Проведите эксперименты. Подготовьте пайплайн обработки данных и построения модели. Jupyter Notebook с проведением экспериментов, bin-файл модели.
5. Продуктивизация. Оберните модель в веб-сервис, чтобы она отвечала на запросы по API. Также сервис должен подниматься в Docker для удобства выкатки. Python-проект с описанным Dockerfile и описанной структурой API.
6. Создание пайплайна дообучения модели. Чтобы модель обновлялась, заберите исторические данные и обучите модель по расписанию.	Граф Airflow (.py-файл) с описанием обучения модели и предварительной обработкой данных.
7. Мониторинг. Проследите, чтобы все сервисы в продакшен-среде контролировались метриками.	.md-файл с описанием метрик. Метрики должны отправляться из кода проекта.
8. Документация. Самая важная часть — опишите процесс обработки данных, создания модели, её выкатки и сопровождения.	Заполненный ReadMe.md
9. Требования и среда. Зафиксируйте случайные состояния и приложите зависимости, с которыми вы работали в рамках прокта. Важно соблюсти воспроизводимость экспериментов.	Оформленный файл requirements.txt

**Имя бакета:** 
s3-student-mle-20250227-68108666c5

**Структура проекта**

```
mle-pr-final/ 
├── airflow/             -- файлы сервиса Airflow
│ ├── config/ 
│ ├── dags/ 
│ ├── logs/ 
│ └── plugins/
│    └── steps/
├── data                 -- исходные данные
├── FastAPI/             -- файлы сервиса FastAPI
│ ├── events
│ ├── features
│ └── recommendations
├── mlflow_server/       -- сервис логирования артефактов     
├── models/              -- локальное сохранение моделей
├── note/           -- juputer nootbok с исследованием (EDA) и обученим модели (REC_SYS)
├── prometheus/        -- сервис мониторинга метрик
└── recommendations/   -- локальное сохранение рекомендаций
```

**Описание данных**

1. category_tree.csv — таблица из двух столбцов: «родительская категория» и «дочерняя категория». 
2. events.csv — таблица с логом событий:
    - timestamp — временная метка события,
    - visitorid — идентификатор пользователя,
    - event — событие (просмотр, добавление в корзину, покупка),
    - itemid — идентификатор товара,
    - transactionid — идентификатор транзакции (покупки).
3. item_properties.csv — таблица со свойствами товаров:
    - timestamp — временная метка добавления свойства,
    - itemid — идентификатор товара,
    - property — свойство товара,
    - value — значение свойства.

## Подготовка виртуальной машины

Склонировать репозиторий проекта:
```
git clone https://github.com/SerhioGo/mle-project-sprint-final.git
```
Перейтив папку проекта
```
cd mle-project-sprint-final
```
Обновление локального индекса пакетов
```
sudo apt-get update
```

Установка расширения для виртуального пространства
```
sudo apt-get install python3.10-venv
```
Создание виртуального пространства
```
python3.10 -m venv .venv_final
```
Инициализацировать окружение
```
source .venv_final/bin/activate
```

Установить в него необходимые Python-пакеты следующей командой
```
pip install -r requirements.txt
```

Дополнительно необходимо устновить следующую зависимость для запуска MLflow
```
pip install psycopg && pip install 'psycopg[binary]'
```

## Руководство к проекту

### Трансляция бизнес-задачи в техническую задачу

Задача простая, необходимо увеличить количество добавлений товаров в корзину с помощью рекомендаций. Это предполагает, что мы должны понимать предпочтения пользователей и предлагать им товары, на основе предпочтений топовых твоаров, или им сопуствующих (похожие по параметрам). Но, забегая вперед отмечу, что построение рекомендательной системы на таких данных достаточно проблематично, мы не знаем какими реальными свойствами обладает тот или иной товар. Приходится работать с цифрами, которые абсолютно безинформативны в данной ситуации, так как в любой покупке может быть добавлен пакет/купон/подарок и т.п., и мы будем предлать клиенту купить ещё один или что-то похожее. Получилось не так радужно, как хотелось бы, так как % добавления в корзину стремится к % погршности сбора данных. 

Таргет: Количество добавлений в корзину. Это основная метрика, она и будет отражать успех просчитанных рекомендаций.

### Разворачивание инфраструктуры обучения модели

Для разворачивания MLflow и остальной инфраструктуры, необходимой для обучения моделей, были выполнены следующие шаги:

1. Установка MLflow и его зависимостей.
2. Настройка серверной части MLflow для хранения метрик и моделей.

Чтобы запуск MLFlow осуществился, при первом запуске необходимо перейти в папку с shell файлом
```
cd mlflow_server
```

Далее дать разрешение на чтение кредов
```
export $(cat .env | xargs)
```

**Тетрадка с исследованием и обучением модели:** mle-pr-final/notebooks/main_research.ipynb

**Логирование эксперимента**

- EXPERIMENT_NAME = 'project_final_one'
- REGISTRY_MODEL_NAME = "ranking_model"

### Проведение EDA

**Exploratory Data Analysis (EDA):**
1. Анализ выявленных эктсремумов в определеннные временные рамки.
2. Сопоставление просмотров и добавлений в корзину товаров, поиск взаимосвязей.
3. Выявление выбросов и аномалий.
4. Поиск и анализ товповых товаров, добавленных в корзину.
5. Оценка отсутствующих признаков и их влияние на анализ.

**Выводы по EDA:**
1. Зачастую, клиент "блуждает" по сайту, просматривая тот или иной товар;
2. Только 2,7% (1,2% совершают покупки) добавляют в корзину товары от общего количества просомтров;
3. Наблюдается взаимосвязть в количестве просмотров от часов и дней недели;
4. При попытке категоризовать признак в привычную матрицу может возникнуть проблема с количеством столбцов, что явно повлияеть на возможность "взлета";

### Генерация признаков и обучение модели

1. RUN_NAME = 'exp_eda'
   - кодирование категориальных признаков categiryid, parentid, userid и itemid;
2. RUN_NAME = 'exp_top_popular'
   - создание рекомендаций для пользователей без истории (холодных): топ-50 просаматриваемых товаров;
3. RUN_NAME = 'exp_similar_items'
   - создание матрицы похожих товаров;
4. RUN_NAME = 'exp_final_recs'
   - персональные рекомендации на основе ранжирования вероятности добавления товара в корзину;
5. RUN_NAME = 'exp_sys_final_metrics'
   - логирование метрик для двух видов рекомендаций: топ-50 по дефолту и персональные рекомендации для пользователей с историей.

Сгенерированы новые признаки:
- istransaction - факт совершения покупки
- available - доступность товара
- rating - отмасштабированный признак популярности товара по количеству просмотров
- day_of_week - день недели, в который было совершено действие
- day - день, в который было совершено действие
- hour - час, в который было совершено действие

### Разворачивание инфраструктуры применения модели

Процесс запуска веб-сервиса и дополнительной инфраструктуры включает:

### Airflow
```
Переход в директорию
cd airflow/

```
Создаст учётную запись с логином и паролем Airflow для веб-интерфейса:
docker compose up airflow-init 
```
Очистим возможный кэш:
docker compose down --volumes --remove-orphans 
```
Запуск Airflow через Docker:
docker compose up --build 
```
Даг обработки данных и обучения модели DAG ():
   /airflow/dags/new_dags.py
```

### MlFlow
```
Переход в директорию
  cd mlflow_server/
```
Загрузки переменных окружения
   export $(cat .env | xargs)
```
Вызов сервиса 
  sh run_mlflow_server.sh
```

### Пример работы сервиса

**Скрипт для симуляции запросов**

Скрипт генерирует 20 запросов с рандомным тайм-аутом
Команда, необходимые для запуска скрипта:
```
python multi_service_load_test.py
```

Адреса сервисов:
- [Mlflow](http://127.0.0.1:5000)
- [Airflow](http://localhost:8080)
- [Приложение](http://localhost:8003)
- [Prometheus](http://localhost:9090)
- [Grafana](http://localhost:3000)